<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="description" content="We propose a mllm which interprets any controllable conditions into structutured captions to achieve high-quality video generation">
    <meta name="keywords" content="Video Generation, Controllable Video Generation, Multimodal LLM, Video Captioning, Intention Interpreting, Video Generation from Text, Video Generation from Image, Video Generation from Video, Video Generation from Motion, Video Generation from Camera Pose">
    <meta property="og:title" content="✨Any2Caption: Interpreting Any Condition to Caption for Controllable Video Generation">
    <meta property="og:description" content="✈️We propose a mllm which interprets any controllable conditions into structutured captions to achieve high-quality video generation">
    <meta property="og:image" content="static/images/logo.png">
    <meta property="og:url" content="https://sqwu.top/Any2Cap/">
    <meta property="og:type" content="website">
    <meta property="og:site_name" content="Any2Caption">
    <meta property="og:locale" content="en_US">
    <meta property="og:locale:alternate" content="zh_CN">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="✨Any2Caption: Interpreting Any Condition to Caption for Controllable Video Generation">
    <meta name="twitter:description" content="✈️We propose a mllm which interprets any controllable conditions into structutured captions to achieve high-quality video generation">
    <meta name="twitter:image" content="static/images/logo.png">
    <meta name="twitter:site" content="@SQWu_Tori">
    <meta name="twitter:creator" content="@SQWu_Tori">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="icon" type="image/png" href="./static/images/logo.png">
    <title>Any2Caption</title>

    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-PYVRSFMDRL');
    </script>

    <link href="https://fonts.cdnfonts.com/css/caveat" rel="stylesheet">

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">
    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <link rel="stylesheet" href="./static/css/index-gradio.css">
    <link rel="stylesheet" href="./static/css/live_theme.css">

    <style>
        @import url('https://fonts.cdnfonts.com/css/caveat');
    </style>

    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/index.js"></script>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>

    <style>
         .scroll-container {
            height: 600px; /* 设置可视高度 */
            overflow-y: auto;
            /* border: 1px solid #ccc; */
        }
        table {
            width: 100%;
            border-collapse: collapse;
            table-layout: fixed; /* 让列宽固定 */
        }
        th, td {
            border: 1px solid black;
            text-align: center;
        }
        thead th {
            position: sticky;
            top: 0;
            background-color: white;
            z-index: 1;
        }
        .col1 { width: 300px; }
        .col2 { width: 200px; }
        .col3 { width: 200px; }
        .col4 { width: 200px; }
        .col5 { width: 700px; }
    </style> 
    
</head>
<body>


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-2 publication-title"><font style="color: rgb(8, 201,185); font-family: CURSIVE;"><em>Any2Caption</em></font> <img src="static/images/logo.png" width="5%">: Interpreting Any Condition to Caption for Controllable Video Generation</h1>
                    
                    <div class="is-size-5 publication-authors">
                        <span class="author-block">
                            <a href="https://chocowu.github.io/">Shengqiong Wu</a><sup>1,2*</sup></span> &nbsp;
                        <span class="author-block">
                            <a href="https://ywcmaike.github.io/">Weicai Ye</a><sup>1, &#9993;</sup></span> &nbsp;
                        <span class="author-block">
                            <a href="https://sqwu.top/Any2Cap/">Jiahao Wang</a><sup>1</sup> </span> &nbsp;
                        <span class="author-block">
                            <a href="https://liuquande.github.io/">Quande Liu</a><sup>1</sup> </span> &nbsp;
                        <span class="author-block">
                            <a href="https://xinntao.github.io/">Xintao Wang</a><sup>1</sup> </span> &nbsp;
                        <span class="author-block">
                            <a href="https://scholar.google.com/citations?user=P6MraaYAAAAJ">Pengfei Wan</a><sup>1</sup></span> &nbsp;
                        <span class="author-block">
                            <a href="https://openreview.net/profile?id=~Di_ZHANG3">Di Zhang</a><sup>1</sup> </span> &nbsp;
                        <span class="author-block">
                            <a href="https://scholar.google.com/citations?user=PXO4ygEAAAAJ">Kun Gai</a><sup>1</sup> </span> &nbsp;
                        <span class="author-block">
                            <a href="https://yanshuicheng.info/">Shuicheng Yan</a><sup>2</sup></span> &nbsp;
                        <span class="author-block">
                            <a href="https://haofei.vip/">Hao Fei</a><sup>2, &#9993;</sup> </span> &nbsp;
                        <span class="author-block">
                            <a href="https://www.chuatatseng.com/">Tat-Seng Chua</a><sup>2</sup></span> &nbsp;
                    </div>
                    <div class="is-size-5 publication-authors" style="margin-top: 10px;">
                        <span class="author-block"><b style="color:#f68946; font-weight:normal">▶ </b><sup>1</sup>Kuaishou Technology</span> &nbsp;
                        <span class="author-block"><b
                                style="color:#008AD7; font-weight:normal">▶ </b><sup>2</sup>National University of Singapore</span> &nbsp;
                    </div>

                    <div class="is-size-5 publication-authors">
                        <span class="author-block" style="font-size: 15px;">(<sup>*</sup>Work done during internship at Kuaishou Technology. </span>
                        <!-- <span class="author-block" style="font-size: 15px;"><sup>\(\dagger\)</sup>Project Lead. </span> -->
                        <span class="author-block" style="font-size: 15px;"><sup>&#9993;</sup>Correspondence)</span>
                    </div>

                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <!-- PDF Link. -->
                            <span class="link-block">
                                <a href="https://arxiv.org/abs/2503.24379" class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon"> <i class="fas fa-file-pdf"></i> </span>
                                    <span>Paper</span>
                                </a>
                            </span>
                            <span class="link-block">
                                <a href="https://huggingface.co/papers/2503.24379" class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon"> <img src="static/images/hf.png"></span>
                                    <span>Huggingface Paper</span>
                                </a>
                            </span>
                        <span class="link-block">
                            <a href="https://github.com/ChocoWu/Any2Caption"
                            class="external-link button is-normal is-rounded is-dark">
                            <span class="icon">
                                <i class="fab fa-github"></i>
                            </span>
                            <span>Code&Data</span>
                            </a>
                        </span>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>


<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-full-width">
                <div class="content has-text-justified">
                    <p><span style="font-family:Papyrus, Fantasy , sans-serif; font-size: x-large;"><b>TL;DR:</b></span> <span style="font-family:Arial, Helvetica, sans-serif, serif; font-size: large;">We propose Any2Caption, a novel framework for controllable video generation from any condition by leveraging MLLMs to interpret diverse inputs into dense,structured captions.</span> </p>
                    <video class="columns is-centered has-text-centered" controls autoplay muted loop width="99%"
                        style="display: block; margin:0 auto">
                        <source src="./static/videos/Any2Cap.mp4" type="video/mp4">
                        Your browser does not support the video tag. 
                    </video>
                </div>
            </div>
        </div>
    </div>
</section>


<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-full-width">
                <h2 class="title is-2">Abstract</h2>
                <div class="content has-text-justified">
                    <p  class="content has-text-justified">
                        To address the bottleneck of accurate user intent interpretation within current video generation community, we present <b><code>Any2Caption</code></b>, a novel framework for controllable video generation from any condition.
                        The key idea is decoupling various condition interpretation steps from the video synthesis step.  
                        By leveraging modern multimodal large language models (MLLMs), <b><code>Any2Caption</code></b> interprets diverse inputs—text, images, videos, and specialized cues such as region, motion, and camera poses—into dense, structured captions that offer backbone video generators with better guidance.  
                        We also introduce <b><code>Any2CapIns</code></b>, a large-scale dataset with 337K instances and 407K conditions for any-condition-to-caption instruction tuning.  
                        Comprehensive evaluations demonstrate significant improvements of our system in controllability and video quality across various arts of existing video generation models. 
                    </p>
                    <div class="content has-text-justified" id="fig1"> 
                        <img class="columns is-centered has-text-centered" src="./static/images/intro.png" alt="Teaser" width="99%"
                                style="display: block; margin:0 auto">
                        <br>
                        <figcaption>
                            <p style="text-align: left;">
                                <font color="061E61">
                                    <b>Figure 1: </b>Any2Caption, an efficient and versatile framework for interpreting diverse conditions to structured captions, which then can be fed into any video generator to generate highly controllable videos.
                                </font>
                            </p>
                        </figcaption>
                    </div>
                </div>
                
            </div>
        </div>
    </div>
</section>



<section class="section" style="background-color: rgb(245,245,245);">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-full-width">
                <h2 class="title is-2">Method</h2>
                <div class="content has-text-justified">
                    <p  class="content has-text-justified">
                        To facilitate the any-to-caption instruction tuning for Any2Caption, we construct Any2CapIns, a large-scale dataset that converts a concise user prompt and diverse
                        non-text conditions into detailed, structured captions. Concretely, the dataset encompasses four main categories of conditions: depth maps, multiple identities, human poses,
                        and camera poses. Through extensive manual labeling combined with automated annotation by GPT-4V, followed by rigorous human verification, we curate a total of <b><code>337K</code></b>
                        high-quality instances, with <b><code>407K</code></b> condition annotations, with the short prompts and structured captions averaging 55 and 231 words, respectively 
                    </p>
                    <div class="content has-text-justified" id="fig1"> 
                        <img class="columns is-centered has-text-centered" src="./static/images/data-construct.png" alt="Teaser" width="99%"
                                style="display: block; margin:0 auto">
                        <br>
                        <figcaption>
                            <p style="text-align: left;">
                                <font color="061E61">
                                    <b>Figure 2: </b>The pipeline for constructing the <b><code>Any2CapIns</code></b> dataset involves three key steps: 1) data collection, 2) structured video caption generation, and 3) user-centric short prompt generation.
                                </font>
                            </p>
                        </figcaption>
                    </div>
                    <p class="content has-text-justified">
                        we propose <b><code>Any2Caption</code></b>, an MLLM-based universal condition interpreter designed not only to handle text, image, and video inputs but also equipped with specialized modules for motion and camera pose inputs. 
                        As illustrated in Fig. 3, <b><code>Any2Caption</code></b> takes as inputs any/diverse condition (or combination), and produces a densely structured caption, which is then passed on to any backend video generator for controllable, high-quality video production.
                    </p>
                    <div class="content has-text-justified" id="fig1"> 
                        <img class="columns is-centered has-text-centered" src="./static/images/any2cap.png" alt="Teaser" width="50%"
                                style="display: block; margin:0 auto">
                        <br>
                        <figcaption>
                            <p style="text-align: left;">
                                <font color="061E61">
                                    <b>Figure 3: </b>Architecture illustration of <b><code>Any2Caption</code></b>, where Qwen2-LLM serves as the backbone and is paired with text, image, video, motion, and camera encoders to produce structured captions.
                                </font>
                            </p>
                        </figcaption>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>


<section class="section">
    <div class="container is-max-desktop">

        <div class="columns is-centered has-text-centered">
            <h2 class="title is-2">Visulizations</h2>
            <br>
        </div>

        <div class="columns is-centered">
            <div class="column is-full-width">
                <h4 class="title is-4" >• Short Caption + Controls → (Structure Caption) → Video Generation</h4>
                <p>To further showcase the model's capacity to understand and leverage input conditions, we directly feed the structured captions—derived from our model's interpretation—into downstream text-to-video generation systems (e.g., CogvideoX and Hunyuan). Here, we show the given short prompt and controllable condtions, and the generated videos only based on the structured captions.</p>
                <div class="content example scroll-container">
                    <table  id="structuredTable" >
                        <thead>
                            <tr >
                                <th class="col1">Short Prompt</th>
                                <th class="col2" colspan="2">Controls</th>
                                <th class="col5" >Structured Caption</th>
                                <th class="col3">Generated Video</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><p><span style="color: rgb(0, 26, 255);">(Hunyuan)</span> A woman in red dress walks in a minimalist, modern room. She is holding two mugs and looks slightly displeased. The room has natural light.</p></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/structured_to_video/811_ids.png"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/structured_to_video/811_depth.gif"></div></td>
                                <td><div class="content has-text-justified"><p>
                                    <b>1. Dense Caption:</b> A woman in a red dress is seen walking through a modern, well-lit interior space. She carries two white mugs—one in each hand—as she moves from a counter area with a coffee machine and pastries toward a windowed section of the room. Her expression suggests she may be in thought or reacting to something unseen. The environment features minimalist design, including white walls and a large black-and-white photo. Natural light streams through the windows, giving the space an open and airy feel.<br>
                                    <b>2. Main Object Caption:</b> The main subject is a middle-aged woman with long, light brown hair and a fair complexion. She wears a sleeveless, form-fitting red dress with a v-neckline and subtle patterning. She carries two white mugs and appears slightly tense or concerned, as shown by her pursed lips and furrowed brows. Her gaze shifts across the room, as though she is searching or reacting to her surroundings.<br>
                                    <b>3. Background Caption:</b> The setting is a sleek, modern room with a minimalist aesthetic. It features clean white walls, a prominent black-and-white photograph of a building, and a countertop with a coffee machine and an arrangement of pastries. The space is brightly lit by natural light from large windows, and the scene transitions toward a section with a broader view of an adjacent office area.<br>
                                    <b>4. Camera Caption:</b> The camera tracks the woman as she walks to the left of the frame. It starts with a slightly low angle and maintains a medium close-up, focusing on her upper body. As she moves, the shot smoothly shifts to a full side profile, keeping her centered within the frame throughout the sequence.<br>
                                    <b>5. Style Caption:</b> The video adopts a clean, polished, and professional visual style. The environment and subject are sharply defined, with bright, even lighting that enhances the modern aesthetic.<br>
                                    <b>6. Action Caption:</b> A woman in a red skirt walked forward with two cups in her hands, and then turned to look at the right.
                                </p></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/structured_to_video/811_ids_hunyuan.gif"></div></td>
                            </tr>
                            <tr>
                                <td><p><span style="color: rgb(0, 26, 255);">(Hunyuan)</span> A young man carrying a messenger bag runs down a narrow, cobblestone street filled with sandbags and crates, suggesting a wartime.</p></td>
                                <td colspan="2"><div class="content has-text-justified"><img width="100%" src="./static/videos/structured_to_video/86_id.jpg"></div></td>
                                <td><div class="content has-text-justified"><p>
                                    <b>1. Dense Caption:</b> A young man is seen running down a narrow cobblestone street, flanked by sandbags and crates that evoke a wartime setting. Dressed in a brown coat and carrying a messenger bag, he moves quickly through a corridor of old European-style buildings. The camera follows his movements, capturing both his hurried pace and the tense atmosphere around him. The scene conveys a strong sense of urgency and determination, set against a quiet, war-ravaged backdrop.<br>
                                    <b>2. Main Object Caption:</b> The central figure is a young man, likely in his late teens or early twenties, with short dark hair and a light complexion. He is dressed in a brown coat and carries a messenger bag across his body. His facial expression is focused and intense, eyes fixed straight ahead, and his mouth slightly open as though he is breathing heavily. His movements are rapid and deliberate, reinforcing the urgency of the situation.<br>
                                    <b>3. Background Caption:</b> The background consists of a narrow cobblestone street lined with historic European-style buildings. Sandbags and wooden crates are scattered along the street, reinforcing the wartime context. The sky is mostly clear with a few scattered clouds, suggesting fair weather. Throughout the video, the background remains unchanged, directing attention to the man's movement.<br>
                                    <b>4. Camera Caption:</b> The camera tracks the man from a consistent eye-level perspective, maintaining a medium distance that captures his full-body movement. As he runs through the street, the camera keeps pace with him, framing both his actions and the surrounding setting to convey a sense of immersion and tension.<br>
                                    <b>5. Style Caption:</b> The video adopts a realistic, documentary-style approach that emphasizes the tension and immediacy of the moment. The contrast between the man's dynamic movement and the still, deserted surroundings intensifies the feeling of a war-torn environment and personal urgency.<br>
                                    <b>6. Action Caption:</b> The man runs swiftly down the street, his footsteps quick and his coat and messenger bag fluttering as he moves. His pace is steady and purposeful, conveying urgency. The static background further highlights the motion of his figure.
                                </p></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/structured_to_video/86_ids_hunyuan.gif"></div></td>
                            </tr>
                            <tr>
                                <td><p><span style="color: rgb(0, 26, 255);">(Hunyuan)</span> A man is adjusting his cap and looking around occasionally. Surroundings include a suburban neighborhood with a brick house, a white van, and an American flag. The weather is sunny, with trees and a clear blue sky. The man seems slightly frustrated, talking to the camera with natural lighting.</p></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/structured_to_video/987_ids.png"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/structured_to_video/987_depth.gif"></div></td>
                                <td><div class="content has-text-justified"><p>
                                    <b>1. Dense Caption:</b> A man dressed in a white shirt and a greenish baseball cap is seen standing outdoors in a quiet suburban neighborhood. He occasionally adjusts his cap and neck while looking around his surroundings. The footage captures him from a close-up angle, highlighting his facial expressions and upper body. In the background, a white van, a brick house, and an American flag are visible, suggesting a bright and sunny day.<br>
                                    <b>2. Main Object Caption:</b> The main subject is a light-skinned man, likely in his late 20s or early 30s, with blond hair, a short beard, and blue eyes. He wears a teal and greenish baseball cap, reflective blue sunglasses, and a white long-sleeved shirt. He has a medium build and appears to be speaking directly to the camera. His expressions, such as a furrowed brow and pursed lips, convey a tone of slight frustration or annoyance, suggesting he may be explaining or commenting on something.    <br>
                                    <b>3. Background Caption:</b> Set in a suburban neighborhood, the background features a white van parked near a brick house, with an American flag displayed prominently. The scene takes place on a sunny day under a clear blue sky, with trees casting partial shade across the area.<br>
                                    <b>4. Camera Caption:</b> The video adopts a casual, candid visual tone with the use of natural lighting, lending an authentic, unfiltered atmosphere to the scene.<br>
                                    <b>5. Style Caption:</b> The video is shot with a handheld camera, positioned at about eye level with the subject. It maintains a close-up framing, focusing on the man's head and shoulders. The camera pans gently—first left, then right, repeating this pattern—capturing the subject’s profile while keeping him centered in the frame, creating an intimate, conversational perspective.<br>
                                    <b>6. Action Caption:</b> The man, dressed in white, is seen speaking while scratching his hand. He then turns his head to the right, maintaining subtle but expressive body language throughout.
                                </p></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/structured_to_video/987_ids_hunyuan.gif"></div></td>
                            </tr>
                            <tr>
                                <td><p><span style="color: rgb(0, 26, 255);">(CogVideoX)</span> A serene winter backyard with snow-covered ground and bare trees, revealing a blue shed with a white garage door and a doghouse. </p></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/structured_to_video/camera_pose_1347.png"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/structured_to_video/1347_depth.gif"></div></td>
                                <td><div class="content has-text-justified"><p>
                                    <b>1. Dense Caption:</b> The video presents a tranquil backyard scene set during winter. It opens with a view of a wooden deck in the foreground before the camera gradually pans to reveal a small blue shed with a white garage door, accompanied by a doghouse to its left. In the center of the frame, a red slide stands out against the snow-covered ground. Surrounding the area are bare trees, reinforcing the cold and stillness of the season. The scene is calm and static, with no visible movement of people or animals, highlighting the peacefulness of a quiet winter day.<br>
                                    <b>2. Main Object Caption:</b> The primary objects in the scene include a blue shed with a white garage door, a doghouse positioned to its left, a red plastic slide, and a wooden deck. These elements are stationary, emphasizing the stillness of the wintry environment.<br>
                                    <b>3. Background Caption:</b> The backdrop features a snow-blanketed backyard enclosed by a white fence, with leafless trees and distant neighboring houses visible. The overcast sky and the untouched snow convey a cold, silent winter atmosphere. The background remains unchanged throughout the video, adding to the sense of stillness.<br>
                                    <b>4. Camera Caption:</b> Filmed from a high-angle perspective, the camera advances forward while gently panning to the right. It maintains a wide shot, encompassing both the house and the surrounding snowy ground, offering a comprehensive view of the serene setting.<br>
                                    <b>5. Style Caption:</b> The video adopts a realistic and unembellished style, authentically portraying the quietude of a winter day.<br>
                                    <b>6. Action Caption:</b> The camera moves forward slowly, capturing the snow-covered ground as well as the house in the distance, contributing to the gradual reveal of the scene.
                                </p></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/structured_to_video/1347_ids_cogvideoX.gif"></div></td>
                            </tr>
                            <tr>
                                <td><p><span style="color: rgb(0, 26, 255);">(CogVideoX)</span>A man gestures while the woman listens. They sit in a sunny park. The camera captures close-up shots of their heads and shoulders. </p></td>
                                <td colspan="2"><div class="content has-text-justified"><img width="100%" src="./static/videos/structured_to_video/971_ids.png"></div></td>
                                <!-- <td><div class="content has-text-justified"><img width="100%" src="./static/videos/structured_to_video/1347_depth.gif"></div></td> -->
                                <td><div class="content has-text-justified"><p>
                                    <b>1. Dense Caption:</b> Two individuals are seated outdoors on a sunny day, engaged in a relaxed conversation. The woman, dressed in a blue and white patterned outfit and wearing a wide-brimmed hat, sits on the left, while the man, in a dark shirt and sunglasses, is on the right. They appear to be in a tranquil outdoor environment, such as a park or garden, with green grass and trees surrounding them. As they talk, the man occasionally gestures, and the woman listens with interest.<br>
                                    <b>2. Main Object Caption:</b> The main subjects include a woman in her late 20s or early 30s with long blonde hair styled in a braid, light skin, and light-colored eyes. She wears a wide-brimmed brown hat, a white and blue patterned top, a necklace, and large hoop earrings. The man, also in his late 20s or early 30s, has light skin, short brown hair, a light beard, and wears a dark gray t-shirt along with dark sunglasses. The woman is seen smiling while speaking, as the man listens with a slight smile, indicating an engaging and friendly exchange.<br>
                                    <b>3. Background Caption:</b> The setting is a sunny, peaceful outdoor area with green grass, leafy trees, and a wooden structure resembling a gazebo or pavilion. The clear sky and natural lighting contribute to the pleasant atmosphere. The background remains still throughout the video, focusing attention on the interaction between the two people.<br>
                                    <b>4. Camera Caption:</b> The footage is slightly shaky, suggesting it was captured handheld. The camera is positioned at eye level with the subjects, maintaining a close-up view of their heads and shoulders. The woman is filmed from a front-side angle, positioned on the left side of the frame, while the man is shown in profile on the right. This framing keeps the conversation central and immersive.<br>
                                    <b>5. Style Caption:</b> The visual style is casual and candid, reflecting a spontaneous moment captured in a calm, outdoor setting. The atmosphere is natural and relaxed, emphasizing genuine human interaction.<br>
                                    <b>6. Action Caption:</b>The woman, wearing a brown hat, begins by talking toward the camera before turning to face the man seated to her right, who is dressed in a dark outfit. Her movement is subtle and conversational.
                                </p></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/structured_to_video/971.gif"></div></td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>
        </div>


        <div class="columns is-centered">
            <div class="column is-full-width">
                <h4 class="title is-4" >• IDs to Video Generation</h4>
                <p>Given multiple identities, and a short prompt, we compared the video generation results with short / structured prompt.</p>
                <div class="content example scroll-container">
                    <table>
                        <thead>
                            <tr >
                                <th class="col1">Short Prompt</th>
                                <th class="col2">Controls</th>
                                <th class="col3">Generated Video w/ short prompt</th>
                                <th class="col3">Generated Video w/ short prompt + Condition Caption</th>
                                <th class="col4">Generated Video w/ structured prompt</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><p>A man in a dark suit stands outdoors, initially looking distressed. The camera captures a close-up of his face, showing a bandage on his forehead. Suddenly, he shifts his stance urgently, turns his head to the side, and raises a handgun with determination. The setting is plain, possibly showing a clear sky, and the lighting suggests it's daytime.
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_to_video/1_ids.png"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_to_video/1_seed666_short.gif"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_to_video/1_seed666.gif"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_to_video/1_seed666_structured.gif"></div></td>
                            </tr>
                            <tr>
                                <td><p> A young girl wearing a school uniform and a young man in casual clothes are walking side by side along a dimly lit concrete wall at night. The girl walks on the left while the boy rides a bicycle on the right. The background is urban and gritty, with warm, moody lighting. The camera follows them closely, capturing a medium close-up shot of their upper bodies from different angles as they move. The scene has a nostalgic and contemplative atmosphere.</p></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_to_video/14_ids.png"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_to_video/14_seed666_short.gif"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_to_video/14_seed666.gif"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_to_video/14_seed666_structured.gif"></div></td>
                            </tr>
                            <tr>
                                <td><p> A woman in a skirt dances on the snow with her hair flying.</p></td>
                                <td colspan="4"><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_to_video/image_reference_34.gif"></div></td>
                            </tr>
                            <tr>
                                <td><p> A whale is floating in the girl's palm, and the camera gradually zooms in.</p></td>
                                <td colspan="4"><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_to_video/image_reference_77.gif"></div></td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>
        </div>

        <div class="columns is-centered">
            <div class="column is-full-width">
                <h4 class="title is-4" >• Camera to Video Generation</h4>
                <p>Given a camera trajectory and a short prompt, we compared the video generation results with short / structured prompt.</p>
                <div class="content example scroll-container">
                    <table>
                        <thead>
                            <tr >
                                <th class="col1">Short Prompt</th>
                                <th class="col2">Controls</th>
                                <th class="col3">Generated Video w/ short prompt</th>
                                <th class="col4">Generated Video w/ structured prompt</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><p>A serene video of a large house with a red roof and a spacious porch, surrounded by lush greenery. A peaceful countryside
                                    setting with vibrant colors and a tranquil atmosphere.</p></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/camera_to_video/camera_pose_10_a2c67c5f22fb5052.png"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/camera_to_video/10_generated-shortcaption.gif"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/camera_to_video/10_generated-structuredcaption.gif"></div></td>
                            </tr>
                            <tr>
                                <td><p> A well-lit dining and living room with elegant and classic decor. The dining table is surrounded by chairs and has a chandelier
                                    above it. There's a wooden cabinet against the wall. The background features a hallway with a staircase and another dining area visible. The
                                    decor includes wooden furniture and framed pictures on the walls.</p></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/camera_to_video/camera_pose_115_52b9e106825852a5.png"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/camera_to_video/115_generated-shortcaption.gif"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/camera_to_video/115_generated-structuredcaption.gif"></div></td>
                            </tr>
                            <tr>
                                <td><p> The scene is bathed in bright sunlight, emphasizing the warm and inviting atmosphere. A modern house with large windows
                                    and a balcony is showcased. Potted plants accent the architectural details. Distant mountains frame the view. Lush greenery surrounds the
                                    scene. The sky is a clear blue, dotted with scattered clouds. A dreamy lens flare effect adds to the serene quality. The overall ambiance is
                                    tranquil and picturesque.</p></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/camera_to_video/camera_pose_129_f6dca34bd73f0e11.png"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/camera_to_video/129_generated-shortcaption.gif"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/camera_to_video/129_generated-structuredcaption.gif"></div></td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>
        </div>

        <div class="columns is-centered">
            <div class="column is-full-width">
                <h4 class="title is-4" >• IDs+Depth to Video Generation</h4>
                <p>Given a depth sequence, multiple identities, and a short prompt, we compared the video generation results with short / structured prompt.</p>
                <div class="content example scroll-container">
                    <table>
                        <thead>
                            <tr >
                                <th class="col1">Short Prompt</th>
                                <th class="col2" colspan="2">Controls</th>
                                <th class="col3">Generated Video w/ short prompt</th>
                                <th class="col4">Generated Video w/ structured prompt</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><p>Young woman with cat ears holding a white cat in a sunlit meadow. Blue butterflies flutter around. Gentle caresses and a serene, magical atmosphere. Trees cast a warm glow. Fixed camera at eye level capturing upper body. Whimsical, enchanting style.</p></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_depth_to_video/1_ids.png"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_depth_to_video/1_depth.gif"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_depth_to_video/1_generated-short.gif"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_depth_to_video/1_generated-structured.gif"></div></td>
                            </tr>
                            <tr>
                                <td><p> A young girl dances in a bright, colorful room. A fluffy dog joyfully mimics her moves. The room features unique, colorful furniture with large windows letting in natural light. The dance is lively and expressive. The atmosphere is cheerful and vibrant. The camera captures full body movements at eye level.</p></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_depth_to_video/4_ids.png"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_depth_to_video/4_depth.gif"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_depth_to_video/4_generated-short.gif"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_depth_to_video/4_generated-structured.gif"></div></td>
                            </tr>
                            <tr>
                                <td><p> A man in a blue sweater and dark jacket looks distressed and scared. He is outdoors in a residential area with trees and buildings in the background. The camera pans smoothly, focusing on his upper body and face from various angles during daylight. The scene captures his intense emotions and movements realistically.</p></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_depth_to_video/31_ids.jpg"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_depth_to_video/31_depth.gif"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_depth_to_video/31_generated-short.gif"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_depth_to_video/31_generated-structured.gif"></div></td>
                            </tr>
                            <tr>
                                <td><p> A man in a dark, workshop-like room, explaining something passionately. Various tools and shoes are on the shelves and workbench. The lighting is dim, creating a serious atmosphere. The camera pans right and then moves forward, focusing on him from a medium close-up shot.</p></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_depth_to_video/46_ids.jpg"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_depth_to_video/46_depth.gif"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_depth_to_video/46_generated-short.gif"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_depth_to_video/46_generated-structured.gif"></div></td>
                            </tr>
                            <tr>
                                <td><p> A ballerina in a black dress with a feathered bodice and a male dancer in a dark, patterned outfit. Detailed stone wall backdrop with ornate metalwork, dim lighting. Emotional and synchronized dance with spins, lifts, arm movements. Dramatic and gothic atmosphere.</p></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_depth_to_video/67_ids.png"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_depth_to_video/67_depth.gif"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_depth_to_video/67_generated-short.gif"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/ids_depth_to_video/67_generated-structured.gif"></div></td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>
        </div>
        
        <div class="columns is-centered">
            <div class="column is-full-width">
                <h4 class="title is-4" >• Style to Video Generation</h4>
                <p>Given a style image and a short prompt, we compared the video generation results with short / structured prompt.</p>
                <div class="content example scroll-container">
                    <table>
                        <thead>
                            <tr >
                                <th class="col1">Short Prompt</th>
                                <th class="col2">Controls</th>
                                <th class="col3">Generated Video w/ short prompt</th>
                                <th class="col4">Generated Video w/ structured prompt</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><p>A lighthouse is beaming across choppy waters.</p></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/style_to_video/800.jpg"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/style_to_video/R0L1_short.gif"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/style_to_video/R0L1_structured.gif"></div></td>
                            </tr>
                            <tr>
                                <td><p> A little girl is reading a book in the beautiful garden.</p></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/style_to_video/0001.jpg"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/style_to_video/R0L144_short.gif"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/style_to_video/R0L144_structured.gif"></div></td>
                                
                            </tr>
                            <tr>
                                <td><p> A street performer playing the guitar.</p></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/style_to_video/oil_paint_2.jpg"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/style_to_video/R0L133_short.gif"></div></td>
                                <td><div class="content has-text-justified"><img width="100%" src="./static/videos/style_to_video/R0L133_structured.gif"></div></td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>
        </div>
    </div>
</section>


<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@inproceedings{wu2025Any2Caption,
    title={Any2Caption: Interpreting Any Condition to Caption for Controllable Video Generation},
    author={Shengqiong Wu and Weicai Ye and Jiahao Wang and Quande Liu and Xintao Wang and Pengfei Wan and Di Zhang and Kun Gai and Shuicheng Yan and Hao Fei and Tat-Seng Chua},
    booktitle={arxiv},
    year={2025}
}
</code></pre>
    </div>
</section>


<footer class="footer">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content">
                    <p style="text-align: center;">
                        The webpage is built based on <a href="https://next-gpt.github.io/">NExT-GPT</a>.
                    </p>
                </div>
            </div>
        </div>
    </div>
</footer>



</body>
</html>
